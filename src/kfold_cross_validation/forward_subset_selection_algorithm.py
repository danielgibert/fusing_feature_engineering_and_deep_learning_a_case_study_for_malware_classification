import argparse
import pandas as pd
import json
import copy
import xgboost as xgb
from xgboost.sklearn import XGBClassifier
from xgboost import cv
import numpy as np

def forward_stepwise_selection(args):
    with open(args.hyperparameters_filepath, "r") as parameters_file:
        hyperparameters = json.load(parameters_file)

    best_filenames_subset = []

    list_of_feature_filenames = ["asm_api_features.csv",
                                 "asm_register_features.csv",
                                 "asm_cnn_opcode_features.csv",
                                 "asm_data_define_features.csv",
                                 "asm_metadata_features.csv",
                                 "asm_misc_features.csv",
                                 "asm_opcode_features.csv",
                                 "asm_pixel_intensity_features.csv",
                                 "asm_section_features.csv",
                                 "asm_symbol_features.csv",
                                 "byte_cnn_entropy_features.csv",
                                 "byte_cnn_img_features.csv",
                                 "byte_entropy_features.csv",
                                 "byte_img_haralick_features.csv",
                                 "byte_img_lbp_features.csv",
                                 "byte_metadata_features.csv",
                                 "byte_unigram_features.csv",
                                 "bytes_cnn_features.csv"]


    best_logloss = 2.19
    best_results = dict()

    with open(args.output_filepath, "w") as output_file:
        break_code = False

        while len(best_filenames_subset) < len(list_of_feature_filenames) and not break_code:
            current_logloss_per_subset = [0.0 for filename in list_of_feature_filenames]
            iteration_filenames_subset = copy.deepcopy(best_filenames_subset)
            for i, feature_filename in enumerate(list_of_feature_filenames):
                current_filenames_subset = copy.deepcopy(iteration_filenames_subset)
                if feature_filename not in current_filenames_subset:
                    current_filenames_subset.append(feature_filename)
                    print("Current subset: {}".format(current_filenames_subset), print(len(current_filenames_subset)))
                    df = pd.read_csv(args.csv_filepath + current_filenames_subset[0])
                    df = df.sort_values(by=['Id'], ascending=False, ignore_index=True)
                    y = df['Class']
                    X = df.drop(columns='Class')

                    if len(current_filenames_subset) > 1:
                        for j in range(1, len(current_filenames_subset)):
                            # print("Adding subset of features {}".format(j))
                            df_ = pd.read_csv(args.csv_filepath + current_filenames_subset[j])
                            df_ = df_.sort_values(by=['Id'], ascending=False, ignore_index=True)

                            df_ = df_.drop(columns=['Class'])
                            # print(df_.columns)
                            X = X.merge(df_, on='Id')
                    X = X.drop(columns='Id')

                    print(list(X.columns), len(list(X.columns)))
                    dtrain = xgb.DMatrix(data=X, label=y)
                    num_rounds = 500
                    early_stoppting_rounds = 5

                    #xgb_model = XGBClassifier(hyperparameters, objective="multi:softprob")
                    history = cv(hyperparameters, dtrain, num_boost_round=num_rounds, nfold=args.K, stratified=True,
                                 metrics=["merror", "mlogloss"], early_stopping_rounds=early_stoppting_rounds)

                    #print(history)
                    print(history.shape, history)
                    if history.shape[0] + 1 < num_rounds:
                        best_row = history.iloc[history.shape[0] + 1 - early_stoppting_rounds]
                    else:
                        best_row = history.tail(-1)
                    current_logloss_per_subset[i] = best_row['test-mlogloss-mean']

                    print("test-mlogloss-mean: {}; test-merror-mean: {}".format(best_row['test-mlogloss-mean'],
                                                                                best_row['test-merror-mean']))
                    # Print current iteration
                    output_file.write("Iteration: {}\n".format(len(current_filenames_subset)))
                    output_file.write("Filenames subset: {}\n".format(current_filenames_subset))
                    output_file.write("Filepath: {}\n".format(args.csv_filepath))
                    output_file.write("test-mlogloss-mean: {}\n".format(best_row['test-mlogloss-mean']))
                    output_file.write("test-merror-mean: {}\n".format(best_row['test-merror-mean']))
                    output_file.write("Number of features: {}\n".format(len(list(X.columns))))
                    #output_file.write("Feature subset: {}\n\n\n\n".format(" ".join(list(X.columns))))

                    if best_row['test-mlogloss-mean'] < best_logloss:
                        best_logloss = best_row['test-mlogloss-mean']
                        best_filenames_subset = current_filenames_subset
                        best_results["filepath"] = args.csv_filepath
                        best_results["hypermarameters"] = hyperparameters
                        best_results["filenames_subset"] = current_filenames_subset
                        best_results['test-mlogloss-mean'] = best_row['test-mlogloss-mean']
                        best_results['test-merror-mean'] = best_row['test-merror-mean']


            greater_loss = 0
            for out in current_logloss_per_subset:
                if out > best_logloss:
                    greater_loss += 1
            if greater_loss == len(current_logloss_per_subset):
                break_code = True

        # Print best results at the end!
        output_file.write("Best results!!!\n")
        output_file.write("Iteration: {}\n".format(len(best_results["filenames_subset"])))
        output_file.write("Filenames subset: {}\n".format(best_results["filenames_subset"]))
        output_file.write("Filepath: {}\n".format(best_results["filepath"]))
        output_file.write("test-mlogloss-mean: {}\n".format(best_results['test-mlogloss-mean']))
        output_file.write("test-merror-mean: {}\n\n\n\n".format(best_results['test-merror-mean']))




if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("csv_filepath", help="Directory where the csv are located", type=str)
    parser.add_argument("hyperparameters_filepath", help="Hyperparameters filepath", type=str)
    parser.add_argument("output_filepath", help="Where the output of the models will be written", type=str)
    parser.add_argument("K", help="Number of folds", type=int)
    args = parser.parse_args()


    forward_stepwise_selection(args)




