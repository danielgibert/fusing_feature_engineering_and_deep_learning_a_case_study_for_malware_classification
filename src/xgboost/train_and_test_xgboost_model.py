import xgboost as xgb
import pandas as pd
import argparse
import sys
sys.path.append("../../")
from src.xgboost.utils import split_dataframe_into_train_and_validation
from scipy.special import softmax
import json


def load_hyperparameters(hyperparameters_filepath):
    with open(hyperparameters_filepath, "r") as hyperparameters_file:
        hyperparameters = json.load(hyperparameters_file)
        return hyperparameters

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("training_filepath", help="CSV containing the features of the training samples", type=str)
    parser.add_argument("test_filepath", help="CSV containing the features of the test samples", type=str)
    parser.add_argument("model_filepath", help="Where the model is stored", type=str)
    parser.add_argument("hyperparameters_filepath", help="Hyperparameters filepath", type=str)
    parser.add_argument("test_output", help="Output of the test samples. File to be submitted into Kaggle", type=str)
    parser.add_argument("--prob_split", help="Prob split", type=float, default=0.9)

    args = parser.parse_args()

    df = pd.read_csv(args.training_filepath)
    df['Class'] = df['Class']
    labels_range = set(df['Class'].values)
    #print("Labels range: {}".format(labels_range))
    #print(len(df.index))
    df_train, df_val = split_dataframe_into_train_and_validation(df,args.prob_split)
    #print(len(df_train.index), len(df_val.index))

    train_labels = df_train["Class"]
    train_features = df_train.drop(columns=["Class", "Id"])
    dtrain = xgb.DMatrix(train_features, label=train_labels)

    val_labels = df_val["Class"]
    val_features = df_val.drop(columns=["Class", "Id"])
    dval = xgb.DMatrix(val_features, label=val_labels)

    hyperparameters = load_hyperparameters(args.hyperparameters_filepath)

    evallist = [(dval, 'eval')]

    bst = xgb.train(hyperparameters, dtrain, hyperparameters["num_rounds"], evallist, early_stopping_rounds=10)
    #bst.dump_model('{}_dump_raw.txt'.format(args.model_filepath), '{}_featmap.txt'.format(args.model_filepath))
    bst.save_model("{}_eta_{}_min_child_weight_{}_gamma_{}_subsample_{}_colsample_bytree_{}_maxdepth_{}.model".format(
        args.model_filepath,
        hyperparameters[
            "eta"],
        hyperparameters[
            "min_child_weight"],
        hyperparameters[
            "gamma"],
        hyperparameters[
            "subsample"],
        hyperparameters[
            "colsample_bytree"],
        hyperparameters[
            "max_depth"]
        ))

    #print(bst.predict(dval))
    df_test = pd.read_csv(args.test_filepath)
    test_ids = df_test['Id'].values

    df_output = pd.DataFrame(columns=["Id", "Prediction1", "Prediction2", "Prediction3", "Prediction4",
                               "Prediction5", "Prediction6", "Prediction7", "Prediction8", "Prediction9"])
    df_output["Id"] = test_ids

    for test_id in test_ids:
        row = df_test.loc[df_test['Id'] == test_id]
        row = row.drop(columns=['Id'])
        dtest = xgb.DMatrix(row)
        ypred = bst.predict(dtest)[0]
        #ypred = softmax(ypred)
        for i in range(1,10):
            df_output.loc[df_output['Id']==test_id, "Prediction{}".format(i)] = ypred[i-1]
    #print(df_output)
        df_output.to_csv(
            args.test_output + "_eta_{}_min_child_weight_{}_gamma_{}_subsample_{}_colsample_bytree_{}_maxdepth_{}.csv".format(hyperparameters["eta"],
                                                                                                                             hyperparameters["min_child_weight"],
                                                                                                                             hyperparameters["gamma"],
                                                                                                                             hyperparameters["subsample"],
                                                                                                                             hyperparameters["colsample_bytree"],
                                                                                                                             hyperparameters["max_depth"]),
                     index=False,
              columns=["Id", "Prediction1", "Prediction2", "Prediction3", "Prediction4",
                       "Prediction5", "Prediction6", "Prediction7", "Prediction8", "Prediction9"])

