import xgboost as xgb
import pandas as pd
import argparse
import sys
sys.path.append("../../")
from src.xgboost.utils import split_dataframe_into_train_and_validation
from scipy.special import softmax
import csv
import json

def load_parameters(hyperparameters_filepath):
    with open(hyperparameters_filepath, "r") as hyperparameters_file:
        hyperparameters = json.load(hyperparameters_file)
        return hyperparameters

def read_K_features(features_filepath):
    columns = []
    with open(features_filepath, "r") as features_file:
        line = features_file.readlines()[0]
        columns = line.strip().split(",")
    return columns

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("training_filepath", help="CSV containing the features of the training samples", type=str)
    parser.add_argument("test_filepath", help="CSV containing the features of the test samples", type=str)
    parser.add_argument("K_features_filepath", help="Filepath containing the K features to use", type=str)
    parser.add_argument("model_filepath", help="Where the model is stored", type=str)
    parser.add_argument("hyperparameters_filepath", help="Hyperparameters filepath", type=str)
    parser.add_argument("test_output", help="Output of the test samples. File to be submitted into Kaggle", type=str)
    parser.add_argument("--prob_split", help="Prob split", type=float, default=0.9)

    args = parser.parse_args()
    columns = read_K_features(args.K_features_filepath)

    df = pd.read_csv(args.training_filepath)
    df['Class'] = df['Class']
    labels_range = set(df['Class'].values)
    #print("Labels range: {}".format(labels_range))
    #print(len(df.index))
    df_train, df_val = split_dataframe_into_train_and_validation(df,args.prob_split)
    #print(len(df_train.index), len(df_val.index))

    train_labels = df_train["Class"]
    train_features = df_train.drop(columns=["Class", "Id"])
    train_features = train_features[columns]


    dtrain = xgb.DMatrix(train_features, label=train_labels)

    val_labels = df_val["Class"]
    val_features = df_val.drop(columns=["Class", "Id"])
    val_features = val_features[columns]
    dval = xgb.DMatrix(val_features, label=val_labels)

    hyperparameters = load_parameters(args.hyperparameters_filepath)

    evallist = [(dval, 'eval')]

    bst = xgb.train(hyperparameters, dtrain, hyperparameters["num_rounds"], evallist, early_stopping_rounds=10)
    #bst.dump_model('{}_dump_raw.txt'.format(args.model_filepath), '{}_featmap.txt'.format(args.model_filepath))
    bst.save_model("{}_eta_{}_min_child_weight_{}_gamma_{}_subsample_{}_colsample_bytree_{}_maxdepth_{}.model".format(
        args.model_filepath,
        hyperparameters[
            "eta"],
        hyperparameters[
            "min_child_weight"],
        hyperparameters[
            "gamma"],
        hyperparameters[
            "subsample"],
        hyperparameters[
            "colsample_bytree"],
        hyperparameters[
            "max_depth"]
        ))

    #print(bst.predict(dval))
    df_test = pd.read_csv(args.test_filepath)
    test_ids = df_test['Id'].values
    df_test = df_test.drop(columns=['Id'])
    df_test = df_test[columns]
    dtest = xgb.DMatrix(df_test)

    output_test = bst.predict(dtest)

    columns = ["Id", "Prediction1", "Prediction2", "Prediction3", "Prediction4",
               "Prediction5", "Prediction6", "Prediction7", "Prediction8", "Prediction9"]
    with open(args.test_output + "_eta_{}_min_child_weight_{}_gamma_{}_subsample_{}_colsample_bytree_{}_maxdepth_{}.csv".format(
                    hyperparameters["eta"],
                    hyperparameters["min_child_weight"],
                    hyperparameters["gamma"],
                    hyperparameters["subsample"],
                    hyperparameters["colsample_bytree"],
                    hyperparameters["max_depth"]), "w") as output_file:
        writer = csv.DictWriter(output_file, fieldnames=columns)
        writer.writeheader()
        for i in range(len(output_test)):
            #print(test_ids[i], output_test[i])
            writer.writerow({"Id":test_ids[i],
                             "Prediction1": output_test[i][0],
                             "Prediction2": output_test[i][1],
                             "Prediction3": output_test[i][2],
                             "Prediction4": output_test[i][3],
                             "Prediction5": output_test[i][4],
                             "Prediction6": output_test[i][5],
                             "Prediction7": output_test[i][6],
                             "Prediction8": output_test[i][7],
                             "Prediction9": output_test[i][8]})
