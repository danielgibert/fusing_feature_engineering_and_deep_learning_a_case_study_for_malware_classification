import xgboost as xgb
import pandas as pd
import argparse
import sys
sys.path.append("../../")
from src.xgboost.utils import split_dataframe_into_train_and_validation
from scipy.special import softmax
import csv
import json
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns


def load_parameters(hyperparameters_filepath):
    with open(hyperparameters_filepath, "r") as hyperparameters_file:
        hyperparameters = json.load(hyperparameters_file)
        return hyperparameters

def show_values_on_bars(axs, h_v="v", space=0.4, type="weight"):
    def _show_on_single_plot(ax):
        if h_v == "v":
            for p in ax.patches:
                _x = p.get_x() + p.get_width() / 2
                _y = p.get_y() + p.get_height()
                if type == "gain":
                    value = ("%.2f" % float(p.get_height()))
                else:
                    value = int(p.get_height())
                ax.text(_x, _y, value, ha="center")
        elif h_v == "h":
            for p in ax.patches:
                _x = p.get_x() + p.get_width() + float(space)
                _y = p.get_y() + p.get_height()
                if type == "gain":
                    value = ("%.2f" % float(p.get_width()))
                else:
                    value = int(p.get_width())
                ax.text(_x, _y, value, ha="left")

    if isinstance(axs, np.ndarray):
        for idx, ax in np.ndenumerate(axs):
            _show_on_single_plot(ax)
    else:
        _show_on_single_plot(axs)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("training_filepath", help="CSV containing the features of the training samples", type=str)
    parser.add_argument("hyperparameters_filepath", help="Hyperparameters filepath", type=str)
    parser.add_argument("features_importance_filepath", help="Feature importance output", type=str)
    parser.add_argument("--prob_split", help="Prob split", type=float, default=0.9)
    parser.add_argument("--num_features", help="Number of features to plot", type=int, default=10)
    parser.add_argument("--importance_type", help="Type of importance", type=str, default="weight")
    parser.add_argument("--remove", help="What to remove from the features", type=str, default="")

    args = parser.parse_args()

    df = pd.read_csv(args.training_filepath)
    df['Class'] = df['Class']
    labels_range = set(df['Class'].values)
    #print("Labels range: {}".format(labels_range))
    #print(len(df.index))
    df_train, df_val = split_dataframe_into_train_and_validation(df,args.prob_split)
    #print(len(df_train.index), len(df_val.index))

    train_labels = df_train["Class"]
    train_features = df_train.drop(columns=["Class", "Id"])
    dtrain = xgb.DMatrix(train_features, label=train_labels)

    val_labels = df_val["Class"]
    val_features = df_val.drop(columns=["Class", "Id"])
    dval = xgb.DMatrix(val_features, label=val_labels)

    hyperparameters = load_parameters(args.hyperparameters_filepath)

    evallist = [(dval, 'eval')]

    bst = xgb.train(hyperparameters, dtrain, hyperparameters["num_rounds"], evallist, early_stopping_rounds=10)
    #bst.dump_model('{}_dump_raw.txt'.format(args.model_filepath), '{}_featmap.txt'.format(args.model_filepath))

    if args.importance_type == "weight":
        weight_scores = bst.get_score(importance_type='weight')
        keys = list(weight_scores.keys())
        clean_keys = [key.replace(args.remove, "") for key in keys]

        values = np.array(list(weight_scores.values()))
        sorted_idx = values.argsort()
        sorted_keys = [clean_keys[idx] for idx in sorted_idx]
        data = pd.DataFrame()
        data["Feature name "] = sorted_keys
        data["Weight"] = values[sorted_idx]
        ax = sns.barplot(x=values[sorted_idx][-args.num_features:], y=sorted_keys[-args.num_features:])
        ax.set(xlabel='Weight', ylabel='Feature')
        plt.xlabel("Weight", size=14)
        plt.ylabel("Feature", size=14)
        show_values_on_bars(ax, "h", 0.3, "weight")
        plt.savefig(args.features_importance_filepath+"weight_{}.png".format(args.num_features),bbox_inches='tight')
    if args.importance_type == "gain":
        gain_scores = bst.get_score(importance_type='gain')
        keys = list(gain_scores.keys())
        clean_keys = [key.replace(args.remove, "") for key in keys]

        values = np.array(list(gain_scores.values()))
        sorted_idx = values.argsort()
        sorted_keys = [clean_keys[idx] for idx in sorted_idx]
        data = pd.DataFrame()
        data["Feature name "] = sorted_keys
        data["Gain"] = values[sorted_idx]
        ax = sns.barplot(x=values[sorted_idx][-args.num_features:], y=sorted_keys[-args.num_features:])
        ax.set(xlabel='Gain', ylabel='Feature')
        plt.xlabel("Gain", size=14)
        plt.ylabel("Feature", size=14)
        show_values_on_bars(ax, "h", 0.3, "gain")
        plt.savefig(args.features_importance_filepath+"gain_{}.png".format(args.num_features),bbox_inches='tight')
    if args.importance_type == "cover":
        cover_scores = bst.get_score(importance_type='cover')
        keys = list(cover_scores.keys())
        clean_keys = [key.replace(args.remove, "") for key in keys]

        values = np.array(list(cover_scores.values()))
        sorted_idx = values.argsort()
        sorted_keys = [clean_keys[idx] for idx in sorted_idx]
        data = pd.DataFrame()
        data["Feature name "] = sorted_keys
        data["Cover"] = values[sorted_idx]
        ax = sns.barplot(x=values[sorted_idx][-args.num_features:], y=sorted_keys[-args.num_features:])
        ax.set(xlabel='Cover', ylabel='Feature')
        plt.xlabel("Cover", size=14)
        plt.ylabel("Feature", size=14)
        show_values_on_bars(ax, "h", 0.3, "weight")
        plt.savefig(args.features_importance_filepath+"cover_{}.png".format(args.num_features),bbox_inches='tight')

