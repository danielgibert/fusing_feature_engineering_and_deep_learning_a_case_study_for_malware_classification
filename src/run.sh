#!/usr/bin/env bash

# Creates the directories to store the feature vectors
mkdir ../data/feature_files/test/feature_concatenation/
mkdir ../data/feature_files/train/feature_concatenation/

# Concatenate the individual feature vectors into a single feature vector
cd preprocessing
sh generate_single_csv_files_almost_all_features.sh
sh generate_single_csv_files_with_subsets_from_forward_stepwise_selection_algorithm.sh
sh generate_single_csv_files_with_various_subsets_of_features.sh

# Train XGBoost model
cd ../xgboost/
mkdir models
python train_and_test_xgboost_model_version2.py ../../data/feature_files/train/feature_concatenation/asm_view_features_plus_bytes_md_unigrams_cnn_without_pixel_intensity.csv ../../data/feature_files/test/feature_concatenation/asm_view_features_plus_bytes_md_unigrams_cnn_without_pixel_intensity.csv models/final_model hyperparameters/best_hyperparameters.json output/final_model_test_predictions.csv
############
## Remember to submit the generated .csv to Kaggle to get the logloss on the test set! You can do it manually or using kaggle API. It is up to you!
############