import tensorflow as tf
import tensorflow_text as text


def _parse_tfrecord_function(example, lookup_table):
    example_fmt = {
            'Id': tf.io.FixedLenFeature([], tf.string),
            'opcodes': tf.io.FixedLenFeature([], tf.string),
            'label': tf.io.FixedLenFeature([], tf.int64)
        }
    parsed = tf.io.parse_single_example(example, example_fmt)
    tokenizer = text.WhitespaceTokenizer()
    tokens = tokenizer.tokenize(parsed['opcodes'])
    IDs = lookup_table.lookup(tokens)
    #mnemonics = tf.io.decode_raw(parsed['mnemonics'], tf.string)
    #label = tf.one_hot(parsed['label'], 9)
    #parsed = tf.io.decode_raw(parsed['mnemonics'], tf.string)
    # decoded_mnemonics = tf.decode_raw(features['mnemonics'], tf.string)
    # decoded_mnemonics = tf.reshape(decoded_mnemonics, [self.parameters['max_sentences'], self.parameters['max_length']])
    # TypeError: Value passed to parameter 'out_type' has DataType string not in list of allowed values:
    #  float16, float32, float64, int32, uint16, uint8, int16, int8, int64
    return parsed['Id'], IDs, parsed['label']



#"../../../data/tfrecords/training.tfrecords"
def make_dataset(filepath, lookup_table, SHUFFLE_BUFFER_SIZE=1024, BATCH_SIZE=32, EPOCHS=5):
    dataset = tf.data.TFRecordDataset(filepath)
    dataset = dataset.shuffle(SHUFFLE_BUFFER_SIZE)
    dataset = dataset.repeat(EPOCHS)
    dataset = dataset.map(lambda x: _parse_tfrecord_function(x, lookup_table))
    dataset = dataset.batch(batch_size=BATCH_SIZE)
    return dataset


#parsed_dataset = make_dataset("../../../data/tfrecords/training.tfrecords")
#for parsed_record in parsed_dataset.take(4):
#    print(repr(parsed_record))