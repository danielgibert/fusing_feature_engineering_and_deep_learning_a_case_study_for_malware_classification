import argparse
import tensorflow as tf
import os
import sys
import csv
from pe_parser.asm_parser import AssemblyParser
from pe_parser.utils import load_vocabulary
from pe_parser.utils import serialize_opcodes_example
import pandas as pd



def microsoft_dataset_to_tfrecords(train_filepath,
                                   test_filepath,
                                   labels_filepath,
                                   tfrecords_filepath,
                                   vocabulary_mapping_filepath,
                                   max_opcodes=20000):

    training_tfwriter = tf.io.TFRecordWriter(tfrecords_filepath + "training.tfrecords")
    validation_tfwriter = tf.io.TFRecordWriter(tfrecords_filepath + "validation.tfrecords")
    test_tfwriter = tf.io.TFRecordWriter(tfrecords_filepath + "test.tfrecords")

    vocabulary_mapping = load_vocabulary(vocabulary_mapping_filepath)

    df_labels = pd.read_csv(labels_filepath)
    df_labels = df_labels.sample(frac=1).reset_index(drop=True)
    print(df_labels)
    total_samples = len(df_labels)
    training_samples= int((total_samples / 10) * 9)
    print(len(df_labels), training_samples)
    #Generate training and validation splits
    train_labels = df_labels[:9781]
    validation_labels = df_labels[9781:]
    print(train_labels, len(train_labels))
    print(validation_labels, len(validation_labels))




    j = 0
    for i in train_labels.index:
        print("{};{}".format(j, train_labels.loc[i, "Id"], train_labels.loc[i, "Class"]))
        asmParser = AssemblyParser()
        asmParser.load_asm_file(train_filepath+train_labels.loc[i, "Id"]+".asm")
        asmParser.extract_assembly_language_source_code(train_filepath+train_labels.loc[i, "Id"]+".asm")
        opcodes = asmParser.get_opcodes_data_as_list(vocabulary_mapping)

        if len(opcodes) < max_opcodes:
            while len(opcodes) < max_opcodes:
                opcodes.append("PAD")
        else:
            opcodes = opcodes[:max_opcodes]
        raw_opcodes = " ".join(opcodes)

        example = serialize_opcodes_example(train_labels.loc[i, "Id"],
                                            raw_opcodes,
                                            int(train_labels.loc[i, "Class"]) - 1)
        training_tfwriter.write(example)
        j += 1

    j = 0
    for i in validation_labels.index:
        print("{};{}".format(j, validation_labels.loc[i, "Id"], validation_labels.loc[i, "Class"]))
        asmParser = AssemblyParser()
        asmParser.load_asm_file(train_filepath + validation_labels.loc[i, "Id"] + ".asm")
        asmParser.extract_assembly_language_source_code(train_filepath + validation_labels.loc[i, "Id"] + ".asm")
        opcodes = asmParser.get_opcodes_data_as_list(vocabulary_mapping)

        if len(opcodes) < max_opcodes:
            while len(opcodes) < max_opcodes:
                opcodes.append("PAD")
        else:
            opcodes = opcodes[:max_opcodes]
        raw_opcodes = " ".join(opcodes)

        example = serialize_opcodes_example(validation_labels.loc[i, "Id"],
                                            raw_opcodes,
                                          int(validation_labels.loc[i, "Class"]) - 1)
        validation_tfwriter.write(example)
        j += 1

    # Test set
    j = 0
    for filename in os.listdir(test_filepath):
        Id = filename[:-4]
        asmParser = AssemblyParser()
        asmParser.load_asm_file(test_filepath + filename)
        asmParser.extract_assembly_language_source_code(test_filepath + filename)
        opcodes = asmParser.get_opcodes_data_as_list(vocabulary_mapping)

        if len(opcodes) < max_opcodes:
            while len(opcodes) < max_opcodes:
                opcodes.append("PAD")
        else:
            opcodes = opcodes[:max_opcodes]
        raw_opcodes_sequence = " ".join(opcodes)

        example = serialize_opcodes_example(Id,
                                            raw_opcodes_sequence,
                                            0)
        test_tfwriter.write(example)
        j += 1


trainLabels = "../../../data/feature_files/train/trainLabels.csv"
train_filepath = "/mnt/hdd1/cerberus_mlw_data/asm/raw/train/"
test_filepath = "/mnt/hdd1/cerberus_mlw_data/asm/raw/test/"
tfrecords_filepath = "/mnt/hdd1/cerberus_mlw_data/tfrecords/opcodes/"
vocabulary_mapping_filepath="vocabulary/mnemonics_vocabulary_mapping_min=3.json"

microsoft_dataset_to_tfrecords(train_filepath,
                               test_filepath,
                               trainLabels,
                               tfrecords_filepath,
                               vocabulary_mapping_filepath,
                               max_opcodes=20000)

